{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2-final"
    },
    "colab": {
      "name": "AM2_T1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoRyu18/AM2_T1/blob/main/AM2_T1_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTLc5BpZrN83"
      },
      "source": [
        "# 1º Trabalho de Aprendizado de Máquina II - UFSCar 2020/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y39FXlO3rN8_"
      },
      "source": [
        "---\n",
        "\n",
        "**Trabalho referente a aplicação de métodos de Classificação multirrótulo em múltiplos datasets.**\n",
        "\n",
        "**Professor**\n",
        "> Diego Furtado Silva\n",
        "\n",
        "**Participantes:**\n",
        "\n",
        ">Leonardo Ryu Takaki -> lrtakaki@estudante.ufscar.br\n",
        "\n",
        ">Augusto Rozendo Mends -> augustorm@estudante.ufscar.br\n",
        "\n",
        ">Fernando Sassi Nunes -> fernando.nunes@estudante.ufscar.br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpa4HFoHrN9A"
      },
      "source": [
        "---\n",
        "\n",
        "- Algoritmos\n",
        " - MLkNN\n",
        " - Relevância binária (BR)\n",
        " - LP (Label Powerset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Base de dados\n",
        " - [Emotions](http://mlkd.csd.auth.gr/publication_details.asp?publicationID=269)\n",
        " -\n",
        " -\n",
        " -\n",
        " -\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNlv1E5GtQPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe18dc5-7684-4d94-9909-7bba7c43e3c7"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EWIkp5orN9B"
      },
      "source": [
        "# importações\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as pyplot\n",
        "\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aLJzzEPrN9C"
      },
      "source": [
        "---\n",
        "## MLkNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aqS7cEprN9D"
      },
      "source": [
        "Explicação rápida do algoritmo aqui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYqlLhatrN9E"
      },
      "source": [
        "def MLkNN_simples(X_train, y_train, X_test, y_test):\n",
        "    classifier = MLkNN(k=3)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
        "\n",
        "def MLkNN_GS(X_train, y_train, X_test, y_test):\n",
        "    parameters = {'k': range(1,3), 's': [0.3, 0.5, 0.7, 1.0]}\n",
        "    score = 'f1_macro'\n",
        "\n",
        "    model = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9XAZXx4rN9F"
      },
      "source": [
        "---\n",
        "## Relevância binária (BR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0olbpyfFrN9G"
      },
      "source": [
        "Explicação rápida do algoritmo aqui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWM0t2TbrN9H"
      },
      "source": [
        "def BR_simples(X_train, y_train, X_test, y_test):\n",
        "    classifier = BinaryRelevance( classifier = SVC(), require_dense = [False, True])\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
        "\n",
        "def BR_GS(X_train, y_train, X_test, y_test):\n",
        "    parameters = [{'classifier': [MultinomialNB()],\n",
        "                   'classifier__alpha': [0.7, 1.0],\n",
        "                  },\n",
        "                  {'classifier': [SVC()],\n",
        "                   'classifier__kernel': ['rbf', 'linear'],\n",
        "                  },\n",
        "                 ]\n",
        "    model = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy')\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwP5bk7GrN9H"
      },
      "source": [
        "---\n",
        "## LP (Label Powerset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E4839_ArN9I"
      },
      "source": [
        "Explicação rápida do algoritmo aqui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3VSkVCgrN9J"
      },
      "source": [
        "def LP_simples(X_train, y_train, X_test, y_test):\n",
        "    classifier = ClassifierChain(classifier = RandomForestClassifier(n_estimators=100), require_dense = [False, True])\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
        "\n",
        "\n",
        "def LP_GS(X_train, y_train, X_test, y_test):\n",
        "    parameters = [{'classifier': [MultinomialNB()],\n",
        "                   'classifier__alpha': [0.7, 1.0],\n",
        "                  },\n",
        "                  {'classifier': [RandomForestClassifier()],\n",
        "                   'classifier__criterion': ['gini', 'entropy'],\n",
        "                   'classifier__n_estimators': [10, 20, 50],\n",
        "                  },\n",
        "                 ]\n",
        "    model = GridSearchCV(LabelPowerset(), parameters, scoring='accuracy')\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
        "\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
        "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
        "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
        "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty09VyRLrN9K"
      },
      "source": [
        "---\n",
        "\n",
        "# Datasets + aplicação dos algoritmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho4-S0CIrN9K"
      },
      "source": [
        "## Emotions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNDcirXLwkxI"
      },
      "source": [
        "Os humanos, por natureza, são afetados emocionalmente pela música. À medida que os bancos de dados de música aumentam de tamanho, a recuperação da música pela emoção se torna uma\n",
        "tarefa importante para várias aplicações, como seleção de música em dispositivos móveis, sistemas de recomendação de música, programas de TV, rádio e musicoterapia.\n",
        "A música pode evocar mais de uma emoção diferente ao mesmo tempo. Desta forma, queremos recuperar uma peça musical baseada em qualquer uma das emoções. A classificação e regressão de rótulo único não podem modelar essa multiplicidade, portanto, utilizamos alguns algoritmos de classificação multirrótulo.\n",
        "\n",
        "Os features extraídos se enquadram em duas categorias: rítmica e timbre.\n",
        "\n",
        "* Features Rítmicos:\n",
        "As características rítmicas foram derivadas da extração das alterações periódicas de um histograma de batida. Um algoritmo que identifica picos foi utilizado e os dois picos mais altos foram selecionados para calcular as amplitudes,\n",
        "seus BPMs (batidas por minuto) e a proporção de alta BPM e baixa BPM. Além disso, 3 recursos foram calculados somando os bins do histograma entre 40-90, 90-140 e 140-\n",
        "250 BPMs respectivamente. Desta forma, temos \n",
        "8 features rítmicos.\n",
        "\n",
        "* Features de timbre:\n",
        "Coeficientes mel-cepstrais (MFCCs) são usados ​​para\n",
        "reconhecimento de fala e modelagem musical. Para derivar features MFCCs, o sinal foi dividido em frames e o espectro de amplitude foi calculado para cada frame. Em seguida, seu logaritmo foi obtido e convertido para a escala de Mel. Finalmente, a\n",
        "transformada discreta de cosseno foi aplicada. No Dataset selecionado, foram utilizados os primeiros 13 MFCCs.\n",
        "Outro conjunto de 3 features relacionados a texturas de timbre foram extraídos da Transformada de Fourier de Curto Termo (FFT): Centróide espectral, rolloff espectral e fluxo espectral.\n",
        "Para cada um dos 16 recursos mencionados acima (13 MFCCs e 3 FFT) foram calculadas a média, o desvio padrão (std),\n",
        "desvio padrão médio (mean std) e desvio padrão\n",
        "de desvio padrão (std std) em todos os frames. Isso levou a um total de 64 recursos de timbre.\n",
        "\n",
        "Temos 6 classes: amazed-surprised, happy-pleased, relaxing-calm, quiet-still, sad-lonely, angry-fearful. Os exemplos foram classificados por três especialistas do sexo masculino de 20, 25 e 30 anos. Apenas as músicas com rotulagem completamente idêntica entre os especialistas foram mantidas para experimentação subsequente. Esse processo levou a um conjunto de dados com 593 músicas classificados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRVGSVDIrN9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "18ae0c67-e662-4e35-a72d-1d9f3a87abfa"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/LeoRyu18/AM2_T1/main/emotions.csv?token=AHW73BL6QJI2YHTKQFMQHTDAKVXNU\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_Centroid</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_Rolloff</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_Flux</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_0</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_1</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_2</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_3</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_4</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_5</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_6</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_7</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_8</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_9</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_10</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_11</th>\n",
              "      <th>Mean_Acc1298_Mean_Mem40_MFCC_12</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_Centroid</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_Rolloff</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_Flux</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_0</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_1</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_2</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_3</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_4</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_5</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_6</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_7</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_8</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_9</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_10</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_11</th>\n",
              "      <th>Mean_Acc1298_Std_Mem40_MFCC_12</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_Centroid</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_Rolloff</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_Flux</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_0</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_1</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_2</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_3</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_4</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_5</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_6</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_7</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_8</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_9</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_10</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_11</th>\n",
              "      <th>Std_Acc1298_Mean_Mem40_MFCC_12</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_Centroid</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_Rolloff</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_Flux</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_0</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_1</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_2</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_3</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_4</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_5</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_6</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_7</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_8</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_9</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_10</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_11</th>\n",
              "      <th>Std_Acc1298_Std_Mem40_MFCC_12</th>\n",
              "      <th>BH_LowPeakAmp</th>\n",
              "      <th>BH_LowPeakBPM</th>\n",
              "      <th>BH_HighPeakAmp</th>\n",
              "      <th>BH_HighPeakBPM</th>\n",
              "      <th>BH_HighLowRatio</th>\n",
              "      <th>BHSUM1</th>\n",
              "      <th>BHSUM2</th>\n",
              "      <th>BHSUM3</th>\n",
              "      <th>amazed-suprised</th>\n",
              "      <th>happy-pleased</th>\n",
              "      <th>relaxing-calm</th>\n",
              "      <th>quiet-still</th>\n",
              "      <th>sad-lonely</th>\n",
              "      <th>angry-aggresive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.034741</td>\n",
              "      <td>0.089665</td>\n",
              "      <td>0.091225</td>\n",
              "      <td>-73.302422</td>\n",
              "      <td>6.215179</td>\n",
              "      <td>0.615074</td>\n",
              "      <td>2.037160</td>\n",
              "      <td>0.804065</td>\n",
              "      <td>1.301409</td>\n",
              "      <td>0.558576</td>\n",
              "      <td>0.672063</td>\n",
              "      <td>0.783788</td>\n",
              "      <td>0.766640</td>\n",
              "      <td>0.458712</td>\n",
              "      <td>0.530384</td>\n",
              "      <td>0.812429</td>\n",
              "      <td>0.028851</td>\n",
              "      <td>0.129039</td>\n",
              "      <td>0.039614</td>\n",
              "      <td>5.762173</td>\n",
              "      <td>1.636819</td>\n",
              "      <td>1.170034</td>\n",
              "      <td>1.051511</td>\n",
              "      <td>0.764163</td>\n",
              "      <td>0.642705</td>\n",
              "      <td>0.617868</td>\n",
              "      <td>0.510265</td>\n",
              "      <td>0.566213</td>\n",
              "      <td>0.509149</td>\n",
              "      <td>0.477275</td>\n",
              "      <td>0.505073</td>\n",
              "      <td>0.463535</td>\n",
              "      <td>0.013519</td>\n",
              "      <td>0.050591</td>\n",
              "      <td>0.009025</td>\n",
              "      <td>8.156257</td>\n",
              "      <td>1.077167</td>\n",
              "      <td>0.624711</td>\n",
              "      <td>0.810244</td>\n",
              "      <td>0.399568</td>\n",
              "      <td>0.279947</td>\n",
              "      <td>0.314215</td>\n",
              "      <td>0.231439</td>\n",
              "      <td>0.345401</td>\n",
              "      <td>0.285389</td>\n",
              "      <td>0.210613</td>\n",
              "      <td>0.321896</td>\n",
              "      <td>0.290551</td>\n",
              "      <td>0.022774</td>\n",
              "      <td>0.095801</td>\n",
              "      <td>0.015057</td>\n",
              "      <td>4.748694</td>\n",
              "      <td>0.536378</td>\n",
              "      <td>0.296306</td>\n",
              "      <td>0.273210</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.105508</td>\n",
              "      <td>0.168246</td>\n",
              "      <td>0.115849</td>\n",
              "      <td>0.136020</td>\n",
              "      <td>0.110514</td>\n",
              "      <td>0.100517</td>\n",
              "      <td>0.118630</td>\n",
              "      <td>0.094923</td>\n",
              "      <td>0.051035</td>\n",
              "      <td>68</td>\n",
              "      <td>0.014937</td>\n",
              "      <td>136</td>\n",
              "      <td>2</td>\n",
              "      <td>0.245457</td>\n",
              "      <td>0.105065</td>\n",
              "      <td>0.405399</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.081374</td>\n",
              "      <td>0.272747</td>\n",
              "      <td>0.085733</td>\n",
              "      <td>-62.584437</td>\n",
              "      <td>3.183163</td>\n",
              "      <td>-0.218145</td>\n",
              "      <td>0.163038</td>\n",
              "      <td>0.620251</td>\n",
              "      <td>0.458514</td>\n",
              "      <td>0.041426</td>\n",
              "      <td>0.308287</td>\n",
              "      <td>0.538152</td>\n",
              "      <td>0.594871</td>\n",
              "      <td>0.734332</td>\n",
              "      <td>0.415489</td>\n",
              "      <td>0.761508</td>\n",
              "      <td>0.066288</td>\n",
              "      <td>0.262370</td>\n",
              "      <td>0.034438</td>\n",
              "      <td>3.480874</td>\n",
              "      <td>1.596532</td>\n",
              "      <td>0.943803</td>\n",
              "      <td>0.804444</td>\n",
              "      <td>0.511229</td>\n",
              "      <td>0.498670</td>\n",
              "      <td>0.523039</td>\n",
              "      <td>0.480916</td>\n",
              "      <td>0.488657</td>\n",
              "      <td>0.483166</td>\n",
              "      <td>0.445187</td>\n",
              "      <td>0.415994</td>\n",
              "      <td>0.405593</td>\n",
              "      <td>0.013621</td>\n",
              "      <td>0.073041</td>\n",
              "      <td>0.010094</td>\n",
              "      <td>1.243981</td>\n",
              "      <td>0.829790</td>\n",
              "      <td>0.252972</td>\n",
              "      <td>0.347831</td>\n",
              "      <td>0.205087</td>\n",
              "      <td>0.168601</td>\n",
              "      <td>0.178009</td>\n",
              "      <td>0.144080</td>\n",
              "      <td>0.178703</td>\n",
              "      <td>0.146937</td>\n",
              "      <td>0.125580</td>\n",
              "      <td>0.128202</td>\n",
              "      <td>0.107007</td>\n",
              "      <td>0.020028</td>\n",
              "      <td>0.066940</td>\n",
              "      <td>0.029483</td>\n",
              "      <td>3.963534</td>\n",
              "      <td>0.382360</td>\n",
              "      <td>0.168389</td>\n",
              "      <td>0.117525</td>\n",
              "      <td>0.098341</td>\n",
              "      <td>0.087046</td>\n",
              "      <td>0.057991</td>\n",
              "      <td>0.059393</td>\n",
              "      <td>0.059457</td>\n",
              "      <td>0.053439</td>\n",
              "      <td>0.067684</td>\n",
              "      <td>0.070075</td>\n",
              "      <td>0.041565</td>\n",
              "      <td>0.295031</td>\n",
              "      <td>70</td>\n",
              "      <td>0.276366</td>\n",
              "      <td>140</td>\n",
              "      <td>2</td>\n",
              "      <td>0.343547</td>\n",
              "      <td>0.276366</td>\n",
              "      <td>0.710924</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.110545</td>\n",
              "      <td>0.273567</td>\n",
              "      <td>0.084410</td>\n",
              "      <td>-65.235325</td>\n",
              "      <td>2.794964</td>\n",
              "      <td>0.639047</td>\n",
              "      <td>1.281297</td>\n",
              "      <td>0.757896</td>\n",
              "      <td>0.489412</td>\n",
              "      <td>0.627636</td>\n",
              "      <td>0.469322</td>\n",
              "      <td>0.644336</td>\n",
              "      <td>0.441556</td>\n",
              "      <td>0.335964</td>\n",
              "      <td>0.290713</td>\n",
              "      <td>0.158538</td>\n",
              "      <td>0.082743</td>\n",
              "      <td>0.215373</td>\n",
              "      <td>0.035970</td>\n",
              "      <td>4.834742</td>\n",
              "      <td>1.213443</td>\n",
              "      <td>0.864034</td>\n",
              "      <td>0.909222</td>\n",
              "      <td>0.780572</td>\n",
              "      <td>0.550833</td>\n",
              "      <td>0.639740</td>\n",
              "      <td>0.573309</td>\n",
              "      <td>0.526312</td>\n",
              "      <td>0.562622</td>\n",
              "      <td>0.538407</td>\n",
              "      <td>0.492292</td>\n",
              "      <td>0.455562</td>\n",
              "      <td>0.029112</td>\n",
              "      <td>0.070433</td>\n",
              "      <td>0.008525</td>\n",
              "      <td>2.759906</td>\n",
              "      <td>0.592634</td>\n",
              "      <td>0.761852</td>\n",
              "      <td>0.568740</td>\n",
              "      <td>0.589827</td>\n",
              "      <td>0.281181</td>\n",
              "      <td>0.437752</td>\n",
              "      <td>0.479889</td>\n",
              "      <td>0.227320</td>\n",
              "      <td>0.296224</td>\n",
              "      <td>0.273855</td>\n",
              "      <td>0.191804</td>\n",
              "      <td>0.198025</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>0.065427</td>\n",
              "      <td>0.029622</td>\n",
              "      <td>3.371796</td>\n",
              "      <td>0.430373</td>\n",
              "      <td>0.172862</td>\n",
              "      <td>0.177523</td>\n",
              "      <td>0.184333</td>\n",
              "      <td>0.095718</td>\n",
              "      <td>0.139323</td>\n",
              "      <td>0.109279</td>\n",
              "      <td>0.090650</td>\n",
              "      <td>0.117886</td>\n",
              "      <td>0.100852</td>\n",
              "      <td>0.079917</td>\n",
              "      <td>0.085821</td>\n",
              "      <td>0.161574</td>\n",
              "      <td>61</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>183</td>\n",
              "      <td>3</td>\n",
              "      <td>0.188693</td>\n",
              "      <td>0.045941</td>\n",
              "      <td>0.457372</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.042481</td>\n",
              "      <td>0.199281</td>\n",
              "      <td>0.093447</td>\n",
              "      <td>-80.305152</td>\n",
              "      <td>5.824409</td>\n",
              "      <td>0.648848</td>\n",
              "      <td>1.754870</td>\n",
              "      <td>1.495532</td>\n",
              "      <td>0.739909</td>\n",
              "      <td>0.809644</td>\n",
              "      <td>0.460945</td>\n",
              "      <td>0.409566</td>\n",
              "      <td>0.680122</td>\n",
              "      <td>0.590405</td>\n",
              "      <td>0.481380</td>\n",
              "      <td>0.621956</td>\n",
              "      <td>0.049939</td>\n",
              "      <td>0.281616</td>\n",
              "      <td>0.044727</td>\n",
              "      <td>6.719538</td>\n",
              "      <td>1.377811</td>\n",
              "      <td>1.265771</td>\n",
              "      <td>0.986178</td>\n",
              "      <td>0.710955</td>\n",
              "      <td>0.706904</td>\n",
              "      <td>0.710147</td>\n",
              "      <td>0.688825</td>\n",
              "      <td>0.699573</td>\n",
              "      <td>0.577976</td>\n",
              "      <td>0.533882</td>\n",
              "      <td>0.501818</td>\n",
              "      <td>0.495368</td>\n",
              "      <td>0.020749</td>\n",
              "      <td>0.106318</td>\n",
              "      <td>0.009108</td>\n",
              "      <td>3.992357</td>\n",
              "      <td>0.656429</td>\n",
              "      <td>0.927692</td>\n",
              "      <td>0.569916</td>\n",
              "      <td>0.378919</td>\n",
              "      <td>0.530714</td>\n",
              "      <td>0.317807</td>\n",
              "      <td>0.308447</td>\n",
              "      <td>0.324934</td>\n",
              "      <td>0.263444</td>\n",
              "      <td>0.359477</td>\n",
              "      <td>0.274257</td>\n",
              "      <td>0.233287</td>\n",
              "      <td>0.032678</td>\n",
              "      <td>0.119480</td>\n",
              "      <td>0.028707</td>\n",
              "      <td>4.125111</td>\n",
              "      <td>0.461304</td>\n",
              "      <td>0.280751</td>\n",
              "      <td>0.246108</td>\n",
              "      <td>0.142805</td>\n",
              "      <td>0.183657</td>\n",
              "      <td>0.124399</td>\n",
              "      <td>0.155513</td>\n",
              "      <td>0.167114</td>\n",
              "      <td>0.113774</td>\n",
              "      <td>0.112815</td>\n",
              "      <td>0.129145</td>\n",
              "      <td>0.122330</td>\n",
              "      <td>0.043012</td>\n",
              "      <td>66</td>\n",
              "      <td>0.206562</td>\n",
              "      <td>132</td>\n",
              "      <td>2</td>\n",
              "      <td>0.102839</td>\n",
              "      <td>0.241934</td>\n",
              "      <td>0.351009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.074550</td>\n",
              "      <td>0.140880</td>\n",
              "      <td>0.079789</td>\n",
              "      <td>-93.697749</td>\n",
              "      <td>5.543229</td>\n",
              "      <td>1.064262</td>\n",
              "      <td>0.899152</td>\n",
              "      <td>0.890336</td>\n",
              "      <td>0.702328</td>\n",
              "      <td>0.490685</td>\n",
              "      <td>0.796904</td>\n",
              "      <td>0.745373</td>\n",
              "      <td>0.911234</td>\n",
              "      <td>0.594429</td>\n",
              "      <td>0.454186</td>\n",
              "      <td>0.384836</td>\n",
              "      <td>0.035751</td>\n",
              "      <td>0.085592</td>\n",
              "      <td>0.029413</td>\n",
              "      <td>4.755293</td>\n",
              "      <td>1.116290</td>\n",
              "      <td>0.926772</td>\n",
              "      <td>0.634988</td>\n",
              "      <td>0.639660</td>\n",
              "      <td>0.552653</td>\n",
              "      <td>0.527708</td>\n",
              "      <td>0.584705</td>\n",
              "      <td>0.696173</td>\n",
              "      <td>0.648611</td>\n",
              "      <td>0.689096</td>\n",
              "      <td>0.643595</td>\n",
              "      <td>0.578063</td>\n",
              "      <td>0.047014</td>\n",
              "      <td>0.136984</td>\n",
              "      <td>0.010356</td>\n",
              "      <td>7.713140</td>\n",
              "      <td>1.592642</td>\n",
              "      <td>1.027190</td>\n",
              "      <td>0.591399</td>\n",
              "      <td>0.565654</td>\n",
              "      <td>0.524420</td>\n",
              "      <td>0.554501</td>\n",
              "      <td>0.606200</td>\n",
              "      <td>0.616760</td>\n",
              "      <td>0.596926</td>\n",
              "      <td>0.524291</td>\n",
              "      <td>0.637971</td>\n",
              "      <td>0.637960</td>\n",
              "      <td>0.036151</td>\n",
              "      <td>0.087741</td>\n",
              "      <td>0.030180</td>\n",
              "      <td>5.085385</td>\n",
              "      <td>0.551937</td>\n",
              "      <td>0.257562</td>\n",
              "      <td>0.159950</td>\n",
              "      <td>0.175855</td>\n",
              "      <td>0.150907</td>\n",
              "      <td>0.142092</td>\n",
              "      <td>0.222804</td>\n",
              "      <td>0.329188</td>\n",
              "      <td>0.251668</td>\n",
              "      <td>0.265049</td>\n",
              "      <td>0.284196</td>\n",
              "      <td>0.189988</td>\n",
              "      <td>0.029308</td>\n",
              "      <td>100</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>200</td>\n",
              "      <td>2</td>\n",
              "      <td>0.195196</td>\n",
              "      <td>0.310801</td>\n",
              "      <td>0.683817</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  Mean_Acc1298_Mean_Mem40_Centroid  ...  sad-lonely  angry-aggresive\n",
              "0   1                          0.034741  ...           0                0\n",
              "1   2                          0.081374  ...           0                1\n",
              "2   3                          0.110545  ...           0                1\n",
              "3   4                          0.042481  ...           0                0\n",
              "4   5                          0.074550  ...           0                0\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC2Kq7HdrN9M"
      },
      "source": [
        "# Pré-processamento \n",
        "\n",
        "df = df.drop(columns=['id'])\n",
        "\n",
        "class_pos = [\"amazed-suprised\", \"happy-pleased\", \"relaxing-calm\", \"quiet-still\", \"sad-lonely\", \"angry-aggresive\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(class_pos, axis = 1), df[class_pos],  test_size = 0.3, random_state = 1)\n",
        "\n",
        "# Normalização\n",
        "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "X_test = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXEXAHd0rN9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb55a651-6b38-49e7-e679-bc8fbecf3cf0"
      },
      "source": [
        "# MLkNN\n",
        "print(\"MLkNN simples:\")\n",
        "MLkNN_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nMLkNN com Grid Search:\")\n",
        "MLkNN_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLkNN simples:\n",
            "Hamming Loss = 0.2144194756554307\n",
            "Acurácia = 0.29213483146067415\n",
            "Precisão = 0.6778115501519757\n",
            "Revocação = 0.6445086705202312\n",
            "\n",
            "MLkNN com Grid Search:\n",
            "Melhores parâmetros = {'k': 1, 's': 0.3} \n",
            "Melhor score = 0.6026791003861202\n",
            "Hamming Loss = 0.23595505617977527\n",
            "Acurácia = 0.2640449438202247\n",
            "Precisão = 0.6320224719101124\n",
            "Revocação = 0.6502890173410405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5i08RHrN9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3171b363-b615-428f-a380-3baa89ddd5ee"
      },
      "source": [
        "# BR\n",
        "print(\"BR simples:\")\n",
        "BR_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nBR com Grid Search:\")\n",
        "BR_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BR simples:\n",
            "Hamming Loss = 0.18726591760299627\n",
            "Acurácia = 0.2640449438202247\n",
            "Precisão = 0.8173913043478261\n",
            "Revocação = 0.5433526011560693\n",
            "\n",
            "BR com Grid Search:\n",
            "Melhores parâmetros = {'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), 'classifier__kernel': 'rbf'} \n",
            "Melhor score = 0.30120481927710846\n",
            "Hamming Loss = 0.18726591760299627\n",
            "Acurácia = 0.2640449438202247\n",
            "Precisão = 0.8173913043478261\n",
            "Revocação = 0.5433526011560693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dYsXQ8srN9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf6d58c-663e-4cf9-958a-d1f0d48096df"
      },
      "source": [
        "# LP\n",
        "print(\"LP simples:\")\n",
        "LP_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nLP com Grid Search:\")\n",
        "LP_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LP simples:\n",
            "Hamming Loss = 0.20318352059925093\n",
            "Acurácia = 0.24157303370786518\n",
            "Precisão = 0.763265306122449\n",
            "Revocação = 0.5404624277456648\n",
            "\n",
            "LP com Grid Search:\n",
            "Melhores parâmetros = {'classifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), 'classifier__criterion': 'entropy', 'classifier__n_estimators': 50} \n",
            "Melhor score = 0.327710843373494\n",
            "Hamming Loss = 0.21722846441947566\n",
            "Acurácia = 0.33146067415730335\n",
            "Precisão = 0.6727272727272727\n",
            "Revocação = 0.6416184971098265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA2TlNw4rN9N"
      },
      "source": [
        "---\n",
        "## FoodTrucks\n",
        "\n",
        "Este dataset (disponível em ) contém resultados de uma pesquisa conduzida em Natal, que visava determinar preferência por certos tipos de food trucks dependendo de fatores diversos. São 407 exemplos no total.\n",
        "\n",
        "As features são:\n",
        "\n",
        "* frequência(numérico): com que frequência uma pessoa come fora, de 1(raramente) a 5(diariamente ou quase diariamente)\n",
        "\n",
        "* tempo (categórico): em que parte do dia costuma comer fora. Os possíveis valores são: manhã,almoço, tarde, happy hour e janta\n",
        "\n",
        "* gasto (numérico): quanto um dado indivíduo costuma gastar, em reais. Os valores determinam os limites dos intervalos: 15,20,30,40,50.\n",
        "\n",
        "* motivação (categórico): o que leva um indivíduo a escolher determinado foodtruck: propaganda, acaso, amigos, redes sociais, internet\n",
        "\n",
        "* gosto, higiene, menu, apresentação, atendimento, ingredientes, lugar disponível,para viagem, variação de escolha, encontros, horários: quanto um dado indivíduo valoriza determinadas qualidades de um foodtruck, numa escala de 1 a 5.\n",
        "\n",
        "* gênero(categórico)\n",
        "\n",
        "* escolaridade(numérico): de sem estudo a phd numa escala de 1 a 5. Vale notar que alunos em processo de graduação são representados por 1.5\n",
        "\n",
        "* renda média(numérico): em termos de salários mínimos, de 1 a 5, sendo 1 menos de 2 e 5 mais de 20\n",
        "\n",
        "* trabalha (binário)\n",
        "\n",
        "* estado civil (categórico)\n",
        "\n",
        "* idade (numérico): agrupados em intervalos, sendo o primeiro <19, os subsequentes de 5 em 5, terminando em um intervalo 50+. Assume os valores de 1 a 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjnTXaF_rN9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "18786631-f1d5-4d6d-932a-e2482c5b7f84"
      },
      "source": [
        "df_food = pd.read_csv(\"https://raw.githubusercontent.com/LeoRyu18/AM2_T1/main/food.csv?token=AHW73BLI3WHUSEIWBNJPWKLAKVW3K\")\n",
        "df_food.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "      <th>time</th>\n",
              "      <th>expenses</th>\n",
              "      <th>motivation</th>\n",
              "      <th>taste</th>\n",
              "      <th>hygiene</th>\n",
              "      <th>menu</th>\n",
              "      <th>presentation</th>\n",
              "      <th>attendance</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>place.to.sit</th>\n",
              "      <th>takeaway</th>\n",
              "      <th>variation</th>\n",
              "      <th>stop.strucks</th>\n",
              "      <th>schedule</th>\n",
              "      <th>gender</th>\n",
              "      <th>age.group</th>\n",
              "      <th>scholarity</th>\n",
              "      <th>average.income</th>\n",
              "      <th>has.work</th>\n",
              "      <th>marital.status</th>\n",
              "      <th>street_food</th>\n",
              "      <th>gourmet</th>\n",
              "      <th>italian_food</th>\n",
              "      <th>brazilian_food</th>\n",
              "      <th>mexican_food</th>\n",
              "      <th>chinese_food</th>\n",
              "      <th>japanese_food</th>\n",
              "      <th>arabic_food</th>\n",
              "      <th>snacks</th>\n",
              "      <th>healthy_food</th>\n",
              "      <th>fitness_food</th>\n",
              "      <th>sweets_desserts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>dinner</td>\n",
              "      <td>30</td>\n",
              "      <td>friend</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>single</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dinner</td>\n",
              "      <td>20</td>\n",
              "      <td>by_chance</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>F</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>married</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>afternoon</td>\n",
              "      <td>15</td>\n",
              "      <td>by_chance</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>single</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>lunch</td>\n",
              "      <td>40</td>\n",
              "      <td>friend</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>single</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>dinner</td>\n",
              "      <td>15</td>\n",
              "      <td>social_network</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>single</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   frequency       time  expenses  ... healthy_food  fitness_food  sweets_desserts\n",
              "0          2     dinner        30  ...            0             0                1\n",
              "1          0     dinner        20  ...            0             0                1\n",
              "2          1  afternoon        15  ...            0             0                0\n",
              "3          0      lunch        40  ...            0             0                0\n",
              "4          0     dinner        15  ...            0             0                0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVZhP4DgrN9P"
      },
      "source": [
        "labels = ['italian_food','brazilian_food','mexican_food','chinese_food','japanese_food','arabic_food','snacks','healthy_food','fitness_food','sweets_desserts','gourmet','street_food']\n",
        "\n",
        "y = df_food[labels]\n",
        "X = df_food.drop(labels,axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0BtyjtrN9P"
      },
      "source": [
        "#encoding de features categóricos\n",
        "X.replace({'dawn':1,'lunch':2,'afternoon':3,'happy_hour':4,'dinner':5\n",
        ",'ads':1,'by_chance':2,'friend':3,'social_network':4,'web':5,\n",
        "'F':1,'M':2,\n",
        "'divorced':1,'married':2,'single':3\n",
        "}, inplace=True)\n",
        "\n",
        "# o único feature que já não vem normalizado numa escala de 1 a 5 é a renda. Não sei se isso é um oversight ou intencional por parte do estudo mas eu decidi normalizar\n",
        "\n",
        "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "X_test = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
        "\n",
        "#Separação treino-teste\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42) \n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9jGhru_rN9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1249d656-8023-4d1b-e11d-f57c1dca029d"
      },
      "source": [
        "print(\"BR simples:\")\n",
        "BR_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nBR com Grid Search:\")\n",
        "BR_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BR simples:\n",
            "Hamming Loss = 0.16666666666666666\n",
            "Acurácia = 0.2647058823529412\n",
            "Precisão = 0.6764705882352942\n",
            "Revocação = 0.2875\n",
            "\n",
            "BR com Grid Search:\n",
            "Melhores parâmetros = {'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), 'classifier__kernel': 'rbf'} \n",
            "Melhor score = 0.28852459016393445\n",
            "Hamming Loss = 0.16666666666666666\n",
            "Acurácia = 0.2647058823529412\n",
            "Precisão = 0.6764705882352942\n",
            "Revocação = 0.2875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a39QdZ-orN9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fde93e-d5e1-4478-c38f-103d5f502469"
      },
      "source": [
        "# MLkNN\n",
        "print(\"MLkNN simples:\")\n",
        "MLkNN_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nMLkNN com Grid Search:\")\n",
        "MLkNN_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLkNN simples:\n",
            "Hamming Loss = 0.18382352941176472\n",
            "Acurácia = 0.13725490196078433\n",
            "Precisão = 0.5449101796407185\n",
            "Revocação = 0.37916666666666665\n",
            "\n",
            "MLkNN com Grid Search:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Melhores parâmetros = {'k': 1, 's': 0.3} \n",
            "Melhor score = 0.22650515289455025\n",
            "Hamming Loss = 0.21160130718954248\n",
            "Acurácia = 0.12745098039215685\n",
            "Precisão = 0.4595744680851064\n",
            "Revocação = 0.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxh5ECk1rN9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763b96cf-6504-4da5-a7a8-7bec04cfb3e2"
      },
      "source": [
        "# LP\n",
        "print(\"LP simples:\")\n",
        "LP_simples(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"\\nLP com Grid Search:\")\n",
        "LP_GS(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LP simples:\n",
            "Hamming Loss = 0.16258169934640523\n",
            "Acurácia = 0.2647058823529412\n",
            "Precisão = 0.6694214876033058\n",
            "Revocação = 0.3375\n",
            "\n",
            "LP com Grid Search:\n",
            "Melhores parâmetros = {'classifier': MultinomialNB(alpha=0.7, class_prior=None, fit_prior=True), 'classifier__alpha': 0.7} \n",
            "Melhor score = 0.2819672131147541\n",
            "Hamming Loss = 0.1781045751633987\n",
            "Acurácia = 0.22549019607843138\n",
            "Precisão = 0.5887096774193549\n",
            "Revocação = 0.30416666666666664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XbcZiorrN9Q"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "znw47prTa8cx",
        "outputId": "f6a79ba4-5331-484d-ef65-5281ae3d424d"
      },
      "source": [
        "df_birds_train = pd.read_csv(\"https://raw.githubusercontent.com/LeoRyu18/AM2_T1/main/csv_result-birds-train.csv\")\n",
        "df_birds_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>audio-ssd1</th>\n",
              "      <th>audio-ssd2</th>\n",
              "      <th>audio-ssd3</th>\n",
              "      <th>audio-ssd4</th>\n",
              "      <th>audio-ssd5</th>\n",
              "      <th>audio-ssd6</th>\n",
              "      <th>audio-ssd7</th>\n",
              "      <th>audio-ssd8</th>\n",
              "      <th>audio-ssd9</th>\n",
              "      <th>audio-ssd10</th>\n",
              "      <th>audio-ssd11</th>\n",
              "      <th>audio-ssd12</th>\n",
              "      <th>audio-ssd13</th>\n",
              "      <th>audio-ssd14</th>\n",
              "      <th>audio-ssd15</th>\n",
              "      <th>audio-ssd16</th>\n",
              "      <th>audio-ssd17</th>\n",
              "      <th>audio-ssd18</th>\n",
              "      <th>audio-ssd19</th>\n",
              "      <th>audio-ssd20</th>\n",
              "      <th>audio-ssd21</th>\n",
              "      <th>audio-ssd22</th>\n",
              "      <th>audio-ssd25</th>\n",
              "      <th>audio-ssd26</th>\n",
              "      <th>audio-ssd27</th>\n",
              "      <th>audio-ssd28</th>\n",
              "      <th>audio-ssd29</th>\n",
              "      <th>audio-ssd30</th>\n",
              "      <th>audio-ssd31</th>\n",
              "      <th>audio-ssd32</th>\n",
              "      <th>audio-ssd33</th>\n",
              "      <th>audio-ssd34</th>\n",
              "      <th>audio-ssd35</th>\n",
              "      <th>audio-ssd36</th>\n",
              "      <th>audio-ssd37</th>\n",
              "      <th>audio-ssd38</th>\n",
              "      <th>audio-ssd39</th>\n",
              "      <th>audio-ssd40</th>\n",
              "      <th>audio-ssd41</th>\n",
              "      <th>...</th>\n",
              "      <th>cluster89</th>\n",
              "      <th>cluster90</th>\n",
              "      <th>cluster91</th>\n",
              "      <th>cluster92</th>\n",
              "      <th>cluster93</th>\n",
              "      <th>cluster94</th>\n",
              "      <th>cluster95</th>\n",
              "      <th>cluster96</th>\n",
              "      <th>cluster97</th>\n",
              "      <th>cluster98</th>\n",
              "      <th>cluster99</th>\n",
              "      <th>cluster100</th>\n",
              "      <th>segments</th>\n",
              "      <th>mean_rect_width</th>\n",
              "      <th>std_rect_width</th>\n",
              "      <th>mean_rect_height</th>\n",
              "      <th>std_rect_height</th>\n",
              "      <th>mean_rect_volume</th>\n",
              "      <th>std_rect_volume</th>\n",
              "      <th>hasSegments</th>\n",
              "      <th>location</th>\n",
              "      <th>Brown</th>\n",
              "      <th>Pacific</th>\n",
              "      <th>Pacific-slope</th>\n",
              "      <th>Red-breasted</th>\n",
              "      <th>Dark-eyed</th>\n",
              "      <th>Olive-sided</th>\n",
              "      <th>Hermit</th>\n",
              "      <th>Chestnut-backed</th>\n",
              "      <th>Varied</th>\n",
              "      <th>Hermit.1</th>\n",
              "      <th>Swainson</th>\n",
              "      <th>Hammond</th>\n",
              "      <th>Western</th>\n",
              "      <th>Black-headed</th>\n",
              "      <th>Golden</th>\n",
              "      <th>Warbling</th>\n",
              "      <th>MacGillivray</th>\n",
              "      <th>Stellar</th>\n",
              "      <th>Common</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.016521</td>\n",
              "      <td>0.039926</td>\n",
              "      <td>0.089632</td>\n",
              "      <td>0.134119</td>\n",
              "      <td>0.170470</td>\n",
              "      <td>0.176872</td>\n",
              "      <td>0.171546</td>\n",
              "      <td>0.182392</td>\n",
              "      <td>0.162482</td>\n",
              "      <td>0.159083</td>\n",
              "      <td>0.164531</td>\n",
              "      <td>0.163366</td>\n",
              "      <td>0.171633</td>\n",
              "      <td>0.219787</td>\n",
              "      <td>0.270805</td>\n",
              "      <td>0.339206</td>\n",
              "      <td>0.327098</td>\n",
              "      <td>0.264581</td>\n",
              "      <td>0.173363</td>\n",
              "      <td>0.131426</td>\n",
              "      <td>0.068158</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.003419</td>\n",
              "      <td>0.004479</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>0.004013</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>0.003314</td>\n",
              "      <td>0.003246</td>\n",
              "      <td>0.002308</td>\n",
              "      <td>0.002129</td>\n",
              "      <td>0.001777</td>\n",
              "      <td>0.002338</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.003741</td>\n",
              "      <td>0.005809</td>\n",
              "      <td>0.006852</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13</td>\n",
              "      <td>16.384615</td>\n",
              "      <td>20.617394</td>\n",
              "      <td>46.769231</td>\n",
              "      <td>71.863118</td>\n",
              "      <td>788.923077</td>\n",
              "      <td>1761.802180</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.006600</td>\n",
              "      <td>0.035984</td>\n",
              "      <td>0.089956</td>\n",
              "      <td>0.123214</td>\n",
              "      <td>0.172273</td>\n",
              "      <td>0.177068</td>\n",
              "      <td>0.165507</td>\n",
              "      <td>0.179655</td>\n",
              "      <td>0.161744</td>\n",
              "      <td>0.163678</td>\n",
              "      <td>0.161606</td>\n",
              "      <td>0.159523</td>\n",
              "      <td>0.171042</td>\n",
              "      <td>0.217206</td>\n",
              "      <td>0.254929</td>\n",
              "      <td>0.307129</td>\n",
              "      <td>0.293592</td>\n",
              "      <td>0.242930</td>\n",
              "      <td>0.151817</td>\n",
              "      <td>0.105817</td>\n",
              "      <td>0.062566</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000972</td>\n",
              "      <td>0.003037</td>\n",
              "      <td>0.004070</td>\n",
              "      <td>0.004311</td>\n",
              "      <td>0.004704</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.003847</td>\n",
              "      <td>0.002940</td>\n",
              "      <td>0.002346</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.001950</td>\n",
              "      <td>0.002063</td>\n",
              "      <td>0.002207</td>\n",
              "      <td>0.002420</td>\n",
              "      <td>0.002521</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.006894</td>\n",
              "      <td>0.017722</td>\n",
              "      <td>0.048062</td>\n",
              "      <td>0.065802</td>\n",
              "      <td>0.103443</td>\n",
              "      <td>0.091397</td>\n",
              "      <td>0.084931</td>\n",
              "      <td>0.088666</td>\n",
              "      <td>0.075676</td>\n",
              "      <td>0.074408</td>\n",
              "      <td>0.074683</td>\n",
              "      <td>0.083202</td>\n",
              "      <td>0.088820</td>\n",
              "      <td>0.125175</td>\n",
              "      <td>0.165580</td>\n",
              "      <td>0.212101</td>\n",
              "      <td>0.217109</td>\n",
              "      <td>0.153888</td>\n",
              "      <td>0.099709</td>\n",
              "      <td>0.074910</td>\n",
              "      <td>0.045928</td>\n",
              "      <td>0.001095</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>0.002134</td>\n",
              "      <td>0.002286</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.001417</td>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.000855</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.000865</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>0.001438</td>\n",
              "      <td>0.002761</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>0.005453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>674.000000</td>\n",
              "      <td>113.137085</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.031046</td>\n",
              "      <td>0.127675</td>\n",
              "      <td>0.221428</td>\n",
              "      <td>0.272707</td>\n",
              "      <td>0.358743</td>\n",
              "      <td>0.349389</td>\n",
              "      <td>0.316029</td>\n",
              "      <td>0.330656</td>\n",
              "      <td>0.310752</td>\n",
              "      <td>0.306288</td>\n",
              "      <td>0.300054</td>\n",
              "      <td>0.304569</td>\n",
              "      <td>0.295422</td>\n",
              "      <td>0.367728</td>\n",
              "      <td>0.398225</td>\n",
              "      <td>0.457381</td>\n",
              "      <td>0.429034</td>\n",
              "      <td>0.330248</td>\n",
              "      <td>0.213530</td>\n",
              "      <td>0.131256</td>\n",
              "      <td>0.075369</td>\n",
              "      <td>0.001508</td>\n",
              "      <td>0.000894</td>\n",
              "      <td>0.005276</td>\n",
              "      <td>0.008511</td>\n",
              "      <td>0.010244</td>\n",
              "      <td>0.010371</td>\n",
              "      <td>0.009083</td>\n",
              "      <td>0.008407</td>\n",
              "      <td>0.006876</td>\n",
              "      <td>0.006512</td>\n",
              "      <td>0.005826</td>\n",
              "      <td>0.004873</td>\n",
              "      <td>0.004481</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.004384</td>\n",
              "      <td>0.004423</td>\n",
              "      <td>0.004448</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.064721</td>\n",
              "      <td>0.226644</td>\n",
              "      <td>0.304482</td>\n",
              "      <td>0.274662</td>\n",
              "      <td>0.346980</td>\n",
              "      <td>0.334063</td>\n",
              "      <td>0.307223</td>\n",
              "      <td>0.324666</td>\n",
              "      <td>0.297070</td>\n",
              "      <td>0.292258</td>\n",
              "      <td>0.287987</td>\n",
              "      <td>0.289535</td>\n",
              "      <td>0.286109</td>\n",
              "      <td>0.354479</td>\n",
              "      <td>0.389812</td>\n",
              "      <td>0.444778</td>\n",
              "      <td>0.407931</td>\n",
              "      <td>0.312861</td>\n",
              "      <td>0.197836</td>\n",
              "      <td>0.122053</td>\n",
              "      <td>0.069657</td>\n",
              "      <td>0.001287</td>\n",
              "      <td>0.002601</td>\n",
              "      <td>0.015984</td>\n",
              "      <td>0.014081</td>\n",
              "      <td>0.008860</td>\n",
              "      <td>0.009464</td>\n",
              "      <td>0.008694</td>\n",
              "      <td>0.007648</td>\n",
              "      <td>0.007977</td>\n",
              "      <td>0.006727</td>\n",
              "      <td>0.005021</td>\n",
              "      <td>0.004376</td>\n",
              "      <td>0.004248</td>\n",
              "      <td>0.004151</td>\n",
              "      <td>0.004636</td>\n",
              "      <td>0.004249</td>\n",
              "      <td>0.004037</td>\n",
              "      <td>0.002778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 280 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  audio-ssd1  audio-ssd2  ...  MacGillivray  Stellar  Common\n",
              "0   1    0.016521    0.039926  ...             0        0       0\n",
              "1   2    0.006600    0.035984  ...             0        0       0\n",
              "2   3    0.006894    0.017722  ...             0        0       0\n",
              "3   4    0.031046    0.127675  ...             0        0       0\n",
              "4   5    0.064721    0.226644  ...             0        0       0\n",
              "\n",
              "[5 rows x 280 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "aqmRUBXRfdx6",
        "outputId": "5350afd6-b11a-4dd2-a89d-5d12322451cf"
      },
      "source": [
        "df_birds_test = pd.read_csv(\"https://raw.githubusercontent.com/LeoRyu18/AM2_T1/main/csv_result-birds-test.csv\")\n",
        "df_birds_test.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>audio-ssd1</th>\n",
              "      <th>audio-ssd2</th>\n",
              "      <th>audio-ssd3</th>\n",
              "      <th>audio-ssd4</th>\n",
              "      <th>audio-ssd5</th>\n",
              "      <th>audio-ssd6</th>\n",
              "      <th>audio-ssd7</th>\n",
              "      <th>audio-ssd8</th>\n",
              "      <th>audio-ssd9</th>\n",
              "      <th>audio-ssd10</th>\n",
              "      <th>audio-ssd11</th>\n",
              "      <th>audio-ssd12</th>\n",
              "      <th>audio-ssd13</th>\n",
              "      <th>audio-ssd14</th>\n",
              "      <th>audio-ssd15</th>\n",
              "      <th>audio-ssd16</th>\n",
              "      <th>audio-ssd17</th>\n",
              "      <th>audio-ssd18</th>\n",
              "      <th>audio-ssd19</th>\n",
              "      <th>audio-ssd20</th>\n",
              "      <th>audio-ssd21</th>\n",
              "      <th>audio-ssd22</th>\n",
              "      <th>audio-ssd25</th>\n",
              "      <th>audio-ssd26</th>\n",
              "      <th>audio-ssd27</th>\n",
              "      <th>audio-ssd28</th>\n",
              "      <th>audio-ssd29</th>\n",
              "      <th>audio-ssd30</th>\n",
              "      <th>audio-ssd31</th>\n",
              "      <th>audio-ssd32</th>\n",
              "      <th>audio-ssd33</th>\n",
              "      <th>audio-ssd34</th>\n",
              "      <th>audio-ssd35</th>\n",
              "      <th>audio-ssd36</th>\n",
              "      <th>audio-ssd37</th>\n",
              "      <th>audio-ssd38</th>\n",
              "      <th>audio-ssd39</th>\n",
              "      <th>audio-ssd40</th>\n",
              "      <th>audio-ssd41</th>\n",
              "      <th>...</th>\n",
              "      <th>cluster89</th>\n",
              "      <th>cluster90</th>\n",
              "      <th>cluster91</th>\n",
              "      <th>cluster92</th>\n",
              "      <th>cluster93</th>\n",
              "      <th>cluster94</th>\n",
              "      <th>cluster95</th>\n",
              "      <th>cluster96</th>\n",
              "      <th>cluster97</th>\n",
              "      <th>cluster98</th>\n",
              "      <th>cluster99</th>\n",
              "      <th>cluster100</th>\n",
              "      <th>segments</th>\n",
              "      <th>mean_rect_width</th>\n",
              "      <th>std_rect_width</th>\n",
              "      <th>mean_rect_height</th>\n",
              "      <th>std_rect_height</th>\n",
              "      <th>mean_rect_volume</th>\n",
              "      <th>std_rect_volume</th>\n",
              "      <th>hasSegments</th>\n",
              "      <th>location</th>\n",
              "      <th>Brown</th>\n",
              "      <th>Pacific</th>\n",
              "      <th>Pacific-slope</th>\n",
              "      <th>Red-breasted</th>\n",
              "      <th>Dark-eyed</th>\n",
              "      <th>Olive-sided</th>\n",
              "      <th>Hermit</th>\n",
              "      <th>Chestnut-backed</th>\n",
              "      <th>Varied</th>\n",
              "      <th>Hermit.1</th>\n",
              "      <th>Swainson</th>\n",
              "      <th>Hammond</th>\n",
              "      <th>Western</th>\n",
              "      <th>Black-headed</th>\n",
              "      <th>Golden</th>\n",
              "      <th>Warbling</th>\n",
              "      <th>MacGillivray</th>\n",
              "      <th>Stellar</th>\n",
              "      <th>Common</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.132445</td>\n",
              "      <td>0.143931</td>\n",
              "      <td>0.227729</td>\n",
              "      <td>0.298556</td>\n",
              "      <td>0.385907</td>\n",
              "      <td>0.378363</td>\n",
              "      <td>0.354708</td>\n",
              "      <td>0.384165</td>\n",
              "      <td>0.360092</td>\n",
              "      <td>0.347465</td>\n",
              "      <td>0.341827</td>\n",
              "      <td>0.349941</td>\n",
              "      <td>0.349431</td>\n",
              "      <td>0.425508</td>\n",
              "      <td>0.470748</td>\n",
              "      <td>0.545955</td>\n",
              "      <td>0.515480</td>\n",
              "      <td>0.439492</td>\n",
              "      <td>0.287173</td>\n",
              "      <td>0.134652</td>\n",
              "      <td>0.082536</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.009794</td>\n",
              "      <td>0.006053</td>\n",
              "      <td>0.008890</td>\n",
              "      <td>0.011114</td>\n",
              "      <td>0.010665</td>\n",
              "      <td>0.010292</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>0.008474</td>\n",
              "      <td>0.008938</td>\n",
              "      <td>0.006323</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>0.005450</td>\n",
              "      <td>0.005856</td>\n",
              "      <td>0.004785</td>\n",
              "      <td>0.005768</td>\n",
              "      <td>0.005577</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.101617</td>\n",
              "      <td>0.130342</td>\n",
              "      <td>0.228117</td>\n",
              "      <td>0.281017</td>\n",
              "      <td>0.365804</td>\n",
              "      <td>0.370122</td>\n",
              "      <td>0.359235</td>\n",
              "      <td>0.388608</td>\n",
              "      <td>0.362013</td>\n",
              "      <td>0.348229</td>\n",
              "      <td>0.342542</td>\n",
              "      <td>0.345851</td>\n",
              "      <td>0.338571</td>\n",
              "      <td>0.424733</td>\n",
              "      <td>0.470891</td>\n",
              "      <td>0.547948</td>\n",
              "      <td>0.516554</td>\n",
              "      <td>0.445265</td>\n",
              "      <td>0.293809</td>\n",
              "      <td>0.140007</td>\n",
              "      <td>0.088689</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.005568</td>\n",
              "      <td>0.006061</td>\n",
              "      <td>0.008843</td>\n",
              "      <td>0.009781</td>\n",
              "      <td>0.009482</td>\n",
              "      <td>0.010100</td>\n",
              "      <td>0.011016</td>\n",
              "      <td>0.009763</td>\n",
              "      <td>0.007648</td>\n",
              "      <td>0.006345</td>\n",
              "      <td>0.005849</td>\n",
              "      <td>0.005672</td>\n",
              "      <td>0.005793</td>\n",
              "      <td>0.005648</td>\n",
              "      <td>0.005650</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>0.003621</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.005148</td>\n",
              "      <td>0.017877</td>\n",
              "      <td>0.042137</td>\n",
              "      <td>0.062124</td>\n",
              "      <td>0.097340</td>\n",
              "      <td>0.088305</td>\n",
              "      <td>0.084337</td>\n",
              "      <td>0.083204</td>\n",
              "      <td>0.074532</td>\n",
              "      <td>0.071497</td>\n",
              "      <td>0.074953</td>\n",
              "      <td>0.077544</td>\n",
              "      <td>0.086848</td>\n",
              "      <td>0.126177</td>\n",
              "      <td>0.209470</td>\n",
              "      <td>0.275132</td>\n",
              "      <td>0.270673</td>\n",
              "      <td>0.238987</td>\n",
              "      <td>0.229216</td>\n",
              "      <td>0.194186</td>\n",
              "      <td>0.094694</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.001294</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>0.002196</td>\n",
              "      <td>0.001996</td>\n",
              "      <td>0.001737</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>0.001275</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.000722</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.000805</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.017121</td>\n",
              "      <td>0.022838</td>\n",
              "      <td>0.013595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>27.235294</td>\n",
              "      <td>44.822526</td>\n",
              "      <td>91.647059</td>\n",
              "      <td>199.564231</td>\n",
              "      <td>2939.823529</td>\n",
              "      <td>9015.550592</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.018792</td>\n",
              "      <td>0.012898</td>\n",
              "      <td>0.027330</td>\n",
              "      <td>0.039521</td>\n",
              "      <td>0.064671</td>\n",
              "      <td>0.068329</td>\n",
              "      <td>0.065799</td>\n",
              "      <td>0.059891</td>\n",
              "      <td>0.048287</td>\n",
              "      <td>0.047820</td>\n",
              "      <td>0.049324</td>\n",
              "      <td>0.055350</td>\n",
              "      <td>0.060587</td>\n",
              "      <td>0.086072</td>\n",
              "      <td>0.111716</td>\n",
              "      <td>0.150919</td>\n",
              "      <td>0.170447</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>0.089051</td>\n",
              "      <td>0.068235</td>\n",
              "      <td>0.043178</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.001177</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.001437</td>\n",
              "      <td>0.001096</td>\n",
              "      <td>0.000785</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.000812</td>\n",
              "      <td>0.000987</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.007008</td>\n",
              "      <td>0.014610</td>\n",
              "      <td>0.033637</td>\n",
              "      <td>0.042604</td>\n",
              "      <td>0.065649</td>\n",
              "      <td>0.065047</td>\n",
              "      <td>0.064553</td>\n",
              "      <td>0.058155</td>\n",
              "      <td>0.048516</td>\n",
              "      <td>0.047021</td>\n",
              "      <td>0.050417</td>\n",
              "      <td>0.054324</td>\n",
              "      <td>0.059212</td>\n",
              "      <td>0.086488</td>\n",
              "      <td>0.110848</td>\n",
              "      <td>0.147765</td>\n",
              "      <td>0.163671</td>\n",
              "      <td>0.130540</td>\n",
              "      <td>0.088572</td>\n",
              "      <td>0.068011</td>\n",
              "      <td>0.043039</td>\n",
              "      <td>0.001082</td>\n",
              "      <td>0.000169</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>0.001409</td>\n",
              "      <td>0.001123</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>0.000874</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>0.000493</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>0.000856</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 280 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  audio-ssd1  audio-ssd2  ...  MacGillivray  Stellar  Common\n",
              "0   1    0.132445    0.143931  ...             0        0       0\n",
              "1   2    0.101617    0.130342  ...             0        0       0\n",
              "2   3    0.005148    0.017877  ...             0        0       0\n",
              "3   4    0.018792    0.012898  ...             0        0       0\n",
              "4   5    0.007008    0.014610  ...             0        0       0\n",
              "\n",
              "[5 rows x 280 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYTOdcXybucJ"
      },
      "source": [
        "labels =  ['Brown', 'Pacific', 'Pacific-slope', 'Red-breasted', ' Dark-eyed', 'Olive-sided', 'Hermit', 'Chestnut-backed', 'Varied', 'Hermit', 'Swainson', 'Hammond', 'Western', 'Black-headed', 'Golden', 'Warbling', 'MacGillivray', 'Stellar', 'Common']\n",
        "\n",
        "y_train_bird = np.array(df_birds_train[labels])\n",
        "y_test_bird = np.array(df_birds_test[labels])\n",
        "\n",
        "X_train = df_birds_train.drop(labels,axis=1)\n",
        "X_test = df_birds_test.drop(labels,axis=1)\n",
        "\n",
        "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
        "X_test = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
        "\n",
        "X_train_bird = np.array(X_train)\n",
        "X_test_bird = np.array(X_test)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgarDy6onfJl"
      },
      "source": [
        "for i in X_train_bird:\n",
        "  for j in i:\n",
        "    if j <0:\n",
        "      print(j) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koZjshVCcqM5",
        "outputId": "9cd5297e-a6d0-4488-85f4-da40b1c00b82"
      },
      "source": [
        "print(\"BR simples:\")\n",
        "BR_simples(X_train_bird, y_train_bird, X_test_bird, y_test_bird)\n",
        "\n",
        "print(\"\\nBR com Grid Search:\")\n",
        "BR_GS(X_train_bird, y_train_bird, X_test_bird, y_test_bird)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BR simples:\n",
            "Hamming Loss = 0.04497311389929933\n",
            "Acurácia = 0.5201238390092879\n",
            "Precisão = 0.9428571428571428\n",
            "Revocação = 0.10749185667752444\n",
            "\n",
            "BR com Grid Search:\n",
            "Melhores parâmetros = {'classifier': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), 'classifier__kernel': 'linear'} \n",
            "Melhor score = 0.5373076923076923\n",
            "Hamming Loss = 0.04790614306664494\n",
            "Acurácia = 0.5139318885448917\n",
            "Precisão = 0.5286343612334802\n",
            "Revocação = 0.39087947882736157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QDBZKKQIcwow",
        "outputId": "00727ac0-43db-4407-b3fe-3adef82e0268"
      },
      "source": [
        "# MLkNN\n",
        "print(\"MLkNN simples:\")\n",
        "MLkNN_simples(X_train_bird, y_train_bird, X_test_bird, y_test_bird)\n",
        "\n",
        "print(\"\\nMLkNN com Grid Search:\")\n",
        "MLkNN_GS(X_train_bird, y_train_bird, X_test_bird, y_test_bird)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLkNN simples:\n",
            "Hamming Loss = 0.046928466677529736\n",
            "Acurácia = 0.5294117647058824\n",
            "Precisão = 0.553072625698324\n",
            "Revocação = 0.32247557003257327\n",
            "\n",
            "MLkNN com Grid Search:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fcf17a6990d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nMLkNN com Grid Search:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mMLkNN_GS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_bird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_bird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_bird\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-8370b81634b6>\u001b[0m in \u001b[0;36mMLkNN_GS\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLkNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Melhores parâmetros =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\nMelhor score =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultilearn/adapt/mlknn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior_prob_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior_prob_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Computing the posterior probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond_prob_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond_prob_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skmultilearn/adapt/mlknn.py\u001b[0m in \u001b[0;36m_compute_cond\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                     \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/dok.py\u001b[0m in \u001b[0;36m_get_intXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_intXslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsbEvBjXc1dZ",
        "outputId": "5678553f-f96a-43c9-e287-990be6aea788"
      },
      "source": [
        "# LP\n",
        "print(\"LP simples:\")\n",
        "LP_simples(X_train_bird, y_train_bird, X_test_bird, y_test_bird)\n",
        "\n",
        "print(\"\\nLP com Grid Search:\")\n",
        "LP_GS(X_train_bird, y_train_bird, X_test_bird, y_test_bird)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LP simples:\n",
            "Hamming Loss = 0.040899462277985986\n",
            "Acurácia = 0.5294117647058824\n",
            "Precisão = 0.8181818181818182\n",
            "Revocação = 0.23452768729641693\n",
            "\n",
            "LP com Grid Search:\n",
            "Melhores parâmetros = {'classifier': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False), 'classifier__criterion': 'entropy', 'classifier__n_estimators': 50} \n",
            "Melhor score = 0.5526923076923077\n",
            "Hamming Loss = 0.0443213296398892\n",
            "Acurácia = 0.5634674922600619\n",
            "Precisão = 0.6073619631901841\n",
            "Revocação = 0.32247557003257327\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}