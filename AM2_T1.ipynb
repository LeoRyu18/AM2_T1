{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1º Trabalho de Aprendizado de Máquina II - UFSCar 2020/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Trabalho referente a aplicação de métodos de Classificação multirrótulo em múltiplos datasets.**\n",
    "\n",
    "**Professor**\n",
    "> Diego Furtado Silva\n",
    "\n",
    "**Participantes:**\n",
    "\n",
    ">Leonardo Ryu Takaki -> lrtakaki@estudante.ufscar.br\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Algoritmos\n",
    " - MLkNN\n",
    " - Relevância binária (BR)\n",
    " - LP (Label Powerset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Base de dados\n",
    " - [Emotions](http://mlkd.csd.auth.gr/publication_details.asp?publicationID=269)\n",
    " -\n",
    " -\n",
    " -\n",
    " -\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importações\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pyplot\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MLkNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação rápida do algoritmo aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLkNN_simples(X_train, y_train, X_test, y_test):\n",
    "    classifier = MLkNN(k=3)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
    "\n",
    "def MLkNN_GS(X_train, y_train, X_test, y_test):\n",
    "    parameters = {'k': range(1,3), 's': [0.3, 0.5, 0.7, 1.0]}\n",
    "    score = 'f1_macro'\n",
    "\n",
    "    model = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Relevância binária (BR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação rápida do algoritmo aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BR_simples(X_train, y_train, X_test, y_test):\n",
    "    classifier = BinaryRelevance( classifier = SVC(), require_dense = [False, True])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
    "\n",
    "def BR_GS(X_train, y_train, X_test, y_test):\n",
    "    parameters = [{'classifier': [MultinomialNB()],\n",
    "                   'classifier__alpha': [0.7, 1.0],\n",
    "                  },\n",
    "                  {'classifier': [SVC()],\n",
    "                   'classifier__kernel': ['rbf', 'linear'],\n",
    "                  },\n",
    "                 ]\n",
    "    model = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LP (Label Powerset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação rápida do algoritmo aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LP_simples(X_train, y_train, X_test, y_test):\n",
    "    classifier = ClassifierChain(classifier = RandomForestClassifier(n_estimators=100), require_dense = [False, True])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n",
    "\n",
    "\n",
    "def LP_GS(X_train, y_train, X_test, y_test):\n",
    "    parameters = [{'classifier': [MultinomialNB()],\n",
    "                   'classifier__alpha': [0.7, 1.0],\n",
    "                  },\n",
    "                  {'classifier': [RandomForestClassifier()],\n",
    "                   'classifier__criterion': ['gini', 'entropy'],\n",
    "                   'classifier__n_estimators': [10, 20, 50],\n",
    "                  },\n",
    "                 ]\n",
    "    model = GridSearchCV(LabelPowerset(), parameters, scoring='accuracy')\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Melhores parâmetros =\", model.best_params_,\"\\nMelhor score =\", model.best_score_)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Hamming Loss =\", metrics.hamming_loss(y_test, predictions))\n",
    "    print(\"Acurácia =\", metrics.accuracy_score(y_test, predictions))\n",
    "    print(\"Precisão =\", metrics.precision_score(y_test, predictions, average='micro'))\n",
    "    print(\"Revocação =\", metrics.recall_score(y_test, predictions, average='micro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Datasets + aplicação dos algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação rápida do Dataset aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Centroid</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Rolloff</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Flux</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_0</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_1</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_2</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_3</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_4</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BH_HighLowRatio</th>\n",
       "      <th>BHSUM1</th>\n",
       "      <th>BHSUM2</th>\n",
       "      <th>BHSUM3</th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-calm</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.034741</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.091225</td>\n",
       "      <td>-73.302422</td>\n",
       "      <td>6.215179</td>\n",
       "      <td>0.615074</td>\n",
       "      <td>2.037160</td>\n",
       "      <td>0.804065</td>\n",
       "      <td>1.301409</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.245457</td>\n",
       "      <td>0.105065</td>\n",
       "      <td>0.405399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.081374</td>\n",
       "      <td>0.272747</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>-62.584437</td>\n",
       "      <td>3.183163</td>\n",
       "      <td>-0.218145</td>\n",
       "      <td>0.163038</td>\n",
       "      <td>0.620251</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343547</td>\n",
       "      <td>0.276366</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.110545</td>\n",
       "      <td>0.273567</td>\n",
       "      <td>0.084410</td>\n",
       "      <td>-65.235325</td>\n",
       "      <td>2.794964</td>\n",
       "      <td>0.639047</td>\n",
       "      <td>1.281297</td>\n",
       "      <td>0.757896</td>\n",
       "      <td>0.489412</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188693</td>\n",
       "      <td>0.045941</td>\n",
       "      <td>0.457372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>-80.305152</td>\n",
       "      <td>5.824409</td>\n",
       "      <td>0.648848</td>\n",
       "      <td>1.754870</td>\n",
       "      <td>1.495532</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.102839</td>\n",
       "      <td>0.241934</td>\n",
       "      <td>0.351009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.140880</td>\n",
       "      <td>0.079789</td>\n",
       "      <td>-93.697749</td>\n",
       "      <td>5.543229</td>\n",
       "      <td>1.064262</td>\n",
       "      <td>0.899152</td>\n",
       "      <td>0.890336</td>\n",
       "      <td>0.702328</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.195196</td>\n",
       "      <td>0.310801</td>\n",
       "      <td>0.683817</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Mean_Acc1298_Mean_Mem40_Centroid  Mean_Acc1298_Mean_Mem40_Rolloff  \\\n",
       "0   1                          0.034741                         0.089665   \n",
       "1   2                          0.081374                         0.272747   \n",
       "2   3                          0.110545                         0.273567   \n",
       "3   4                          0.042481                         0.199281   \n",
       "4   5                          0.074550                         0.140880   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_Flux  Mean_Acc1298_Mean_Mem40_MFCC_0  \\\n",
       "0                      0.091225                      -73.302422   \n",
       "1                      0.085733                      -62.584437   \n",
       "2                      0.084410                      -65.235325   \n",
       "3                      0.093447                      -80.305152   \n",
       "4                      0.079789                      -93.697749   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_1  Mean_Acc1298_Mean_Mem40_MFCC_2  \\\n",
       "0                        6.215179                        0.615074   \n",
       "1                        3.183163                       -0.218145   \n",
       "2                        2.794964                        0.639047   \n",
       "3                        5.824409                        0.648848   \n",
       "4                        5.543229                        1.064262   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_3  Mean_Acc1298_Mean_Mem40_MFCC_4  \\\n",
       "0                        2.037160                        0.804065   \n",
       "1                        0.163038                        0.620251   \n",
       "2                        1.281297                        0.757896   \n",
       "3                        1.754870                        1.495532   \n",
       "4                        0.899152                        0.890336   \n",
       "\n",
       "   Mean_Acc1298_Mean_Mem40_MFCC_5  ...  BH_HighLowRatio    BHSUM1    BHSUM2  \\\n",
       "0                        1.301409  ...                2  0.245457  0.105065   \n",
       "1                        0.458514  ...                2  0.343547  0.276366   \n",
       "2                        0.489412  ...                3  0.188693  0.045941   \n",
       "3                        0.739909  ...                2  0.102839  0.241934   \n",
       "4                        0.702328  ...                2  0.195196  0.310801   \n",
       "\n",
       "     BHSUM3  amazed-suprised  happy-pleased  relaxing-calm  quiet-still  \\\n",
       "0  0.405399                0              1              1            0   \n",
       "1  0.710924                1              0              0            0   \n",
       "2  0.457372                0              1              0            0   \n",
       "3  0.351009                0              0              1            0   \n",
       "4  0.683817                0              0              0            1   \n",
       "\n",
       "   sad-lonely  angry-aggresive  \n",
       "0           0                0  \n",
       "1           0                1  \n",
       "2           0                1  \n",
       "3           0                0  \n",
       "4           0                0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento \n",
    "\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "class_pos = [\"amazed-suprised\", \"happy-pleased\", \"relaxing-calm\", \"quiet-still\", \"sad-lonely\", \"angry-aggresive\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(class_pos, axis = 1), df[class_pos],  test_size = 0.3, random_state = 1)\n",
    "\n",
    "# Normalização\n",
    "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "X_test = preprocessing.MinMaxScaler().fit_transform(X_test)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLkNN simples:\n",
      "Hamming Loss = 0.2144194756554307\n",
      "Acurácia = 0.29213483146067415\n",
      "Precisão = 0.6778115501519757\n",
      "Revocação = 0.6445086705202312\n",
      "\n",
      "MLkNN com Grid Search:\n",
      "Melhores parâmetros = {'k': 1, 's': 0.3} \n",
      "Melhor score = 0.6026791003861202\n",
      "Hamming Loss = 0.23595505617977527\n",
      "Acurácia = 0.2640449438202247\n",
      "Precisão = 0.6320224719101124\n",
      "Revocação = 0.6502890173410405\n"
     ]
    }
   ],
   "source": [
    "# MLkNN\n",
    "print(\"MLkNN simples:\")\n",
    "MLkNN_simples(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nMLkNN com Grid Search:\")\n",
    "MLkNN_GS(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR simples:\n",
      "Hamming Loss = 0.18726591760299627\n",
      "Acurácia = 0.2640449438202247\n",
      "Precisão = 0.8173913043478261\n",
      "Revocação = 0.5433526011560693\n",
      "\n",
      "BR com Grid Search:\n",
      "Melhores parâmetros = {'classifier': SVC(), 'classifier__kernel': 'rbf'} \n",
      "Melhor score = 0.30120481927710846\n",
      "Hamming Loss = 0.18726591760299627\n",
      "Acurácia = 0.2640449438202247\n",
      "Precisão = 0.8173913043478261\n",
      "Revocação = 0.5433526011560693\n"
     ]
    }
   ],
   "source": [
    "# BR\n",
    "print(\"BR simples:\")\n",
    "BR_simples(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nBR com Grid Search:\")\n",
    "BR_GS(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP simples:\n",
      "Hamming Loss = 0.19194756554307116\n",
      "Acurácia = 0.2752808988764045\n",
      "Precisão = 0.7854251012145749\n",
      "Revocação = 0.5606936416184971\n",
      "\n",
      "LP com Grid Search:\n",
      "Melhores parâmetros = {'classifier': RandomForestClassifier(criterion='entropy', n_estimators=50), 'classifier__criterion': 'entropy', 'classifier__n_estimators': 50} \n",
      "Melhor score = 0.3397590361445783\n",
      "Hamming Loss = 0.20599250936329588\n",
      "Acurácia = 0.3258426966292135\n",
      "Precisão = 0.6863905325443787\n",
      "Revocação = 0.6705202312138728\n"
     ]
    }
   ],
   "source": [
    "# LP\n",
    "print(\"LP simples:\")\n",
    "LP_simples(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nLP com Grid Search:\")\n",
    "LP_GS(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
